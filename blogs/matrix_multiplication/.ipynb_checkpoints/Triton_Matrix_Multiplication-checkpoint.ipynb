{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d7d6c8-e214-428a-bb28-ee8aeae9e984",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Matrix Multiplication in Triton\"\n",
    "categories: [triton]\n",
    "date: \"2025-01-22\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580085e-a2c9-444b-94bb-034bd8675f68",
   "metadata": {},
   "source": [
    "Matrix multiplication is defined for two matrices when the number of columns in the first matrix equals the number of rows in the second matrix. For example, if matrix (A) has dimensions (m x k), then matrix (B) must have dimensions (k x n) for the multiplication to be valid. The resulting matrix (C) will have dimensions (m x n). \n",
    "\n",
    "Each element of (C) is computed as the sum of the products of corresponding elements from a row of (A) and a column of (B). In other words, the value at position C[i][j] is obtained by multiplying each element of the i-th row of (A) with the corresponding element of the j-th column of (B), and then summing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e9f02-3016-4443-95c9-5f41c00ae4f0",
   "metadata": {},
   "source": [
    "## Understanding matmul kernel\n",
    "\n",
    "Suppose we have matrix A with dimension (M x K) and matrix B with dimension (K X N) then our resulting matrix C has dimension (M x N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719559d-0172-47c8-b827-71b4110a0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def matmul_kernel(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "        # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`\n",
    "        # by to get the element one row down (A has M rows).\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,  #\n",
    "        ACTIVATION: tl.constexpr  #\n",
    "):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef316a2-6aec-450d-9b5c-63cf01e9503f",
   "metadata": {},
   "source": [
    "The `@triton.jit` decorator in Triton is used to compile a Python function as a Triton kernel allowing it to be executed efficiently in GPU. The `a_ptr`, `b_ptr` and `c_ptr` are the pointers to matrices A, B and C respectively. These contain the starting memory address in GPU global memory for the matrix i.e. a_ptr contains the memory address for A[0][0]. In GPU, matrices are stored in row-major order, which means that every elemets of our 2D matrix are stored in 1D memory layout. So for this reason we require stride to get next row element or column element of our matrix. `stride_am` represents number of elements in 1D memory layout to skip so that we obtain the element of our next row in matrix A and similarly `stride_ak` represents number of elements in 1D memory layout to skip so that we obtain the element of our next column in matrix A, which is usually 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7925e4-ef34-49f9-91dd-d38bbbf0e2bc",
   "metadata": {},
   "source": [
    "[![2D row-major memory layout](row-major-2D.png)](https://eli.thegreenplace.net/2015/memory-layout-of-multi-dimensional-arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72168652-0fa2-47f4-ad05-df2424b89c28",
   "metadata": {},
   "source": [
    "The `BLOCK_SIZE_M`, `BLOCK_SIZE_N` and `BLOCK_SIZE_K` the size of our block along those axises. `GROUP_SIZE_M` is the maximum number of rows per group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c99e2-2116-4a6c-b5e6-d42dcada65d6",
   "metadata": {},
   "source": [
    "### L2 Cache optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed416a08-5d63-42eb-9445-4caa5e53d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # -----------------------------------------------------------\n",
    "    # Map program ids `pid` to the block of C it should compute.\n",
    "    # This is done in a grouped ordering to promote L2 data reuse.\n",
    "    # See above `L2 Cache Optimizations` section for details.\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c53eae-b8a4-4312-b018-530bae06823d",
   "metadata": {},
   "source": [
    "The `num_pid_m` is the number of blocks in the M axis and `num_pid_n` is the number of blocks in the N axis. Suppose `N = 384` and `BLOCK_SIZE_N = 128` then `num_pid_n = ceil(384/128) = 3` i.e. there are 3 blocks in a row. Let's consider `GROUP_SIZE_M = 2` then `num_pid_in_group = 2 * 3 = 6` i.e a group in our C matrix contains 6 program ids (each block is 1 pid). For a given program id we can find the group in which it belongs to by `group_id = pid // num_pid_in_group`. Then we calculate the starting row index in matrix A and C for the current group of thread blocks using `first_pid_m = group_id * GROUP_SIZE_M`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d32493-791d-478b-a289-03227380a854",
   "metadata": {},
   "source": [
    "![Blocks and group](group.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac178c5f-22d8-44e0-858a-89eec25e8ff7",
   "metadata": {},
   "source": [
    "The `group_size_m` is a runtime variable that calculates the actual number of rows a group processes, since there can be edge cases when total rows is less then `GROUP_SIZE_M`. The example table below shows the calculation of `pid_m` and `pid_n` for `num_pid_m = 3`, `num_pid_n = 3`, and `GROUP_SIZE_M = 2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bec6f7-d1d2-49b9-b90b-34c516bc477a",
   "metadata": {},
   "source": [
    "| pid | group_id | pid_m | pid_n |\n",
    "|-----|----------|-------|-------|\n",
    "|  0  |    0     |   0   |   0   |\n",
    "|  1  |    0     |   1   |   0   |\n",
    "|  2  |    0     |   0   |   1   |\n",
    "|  3  |    0     |   1   |   1   |\n",
    "|  4  |    0     |   0   |   2   |\n",
    "|  5  |    0     |   1   |   2   |\n",
    "|  6  |    1     |   2   |   0   |\n",
    "|  7  |    1     |   2   |   1   |\n",
    "|  8  |    1     |   2   |   2   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774eab6-e0da-493a-89f6-421869f8d399",
   "metadata": {},
   "source": [
    "Calculating our output matrix in grouped ordering instead of row-major ordering has an added benefit of loading fewer number of blocks into our cache as seen in the picture from official triton tutorial.\n",
    "\n",
    "[![Group ordering vs row-major ordering](grouped_vs_row_major_ordering.png)](https://triton-lang.org/main/_images/grouped_vs_row_major_ordering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913056f8-9089-4b2e-8e4c-e6dc05b8b2c5",
   "metadata": {},
   "source": [
    "### Pointer Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd59578-82db-429b-9ce8-df95abbabd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Accessing blocks in matrix A and B\"\"\"\n",
    "    # ----------------------------------------------------------\n",
    "    # Create pointers for the first blocks of A and B.\n",
    "    # We will advance this pointer as we move in the K direction\n",
    "    # and accumulate\n",
    "    # `a_ptrs` is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers\n",
    "    # `b_ptrs` is a block of [BLOCK_SIZE_K, BLOCK_SIZE_N] pointers\n",
    "    # See above `Pointer Arithmetic` section for details\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783af79-3415-45aa-a76c-e73e49b72790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
